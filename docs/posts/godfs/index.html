<!doctype html>
<html lang="en">
<head><meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta content='text/html; charset=utf-8' http-equiv='content-type' />

  <title>GoDFS - a simple Distributed FileSystem written in Go - Rounak&#39;s Blog</title>
  <meta content='GoDFS - a simple Distributed FileSystem written in Go - Rounak&#39;s Blog' property='title' />
  <meta content='GoDFS - a simple Distributed FileSystem written in Go - Rounak&#39;s Blog' property='og:title' />


<meta property="og:description" content="Redundancy is the key in software engineering ~Paul Klint
 I&rsquo;ve been midway through Designing Data-Intensive Applications and implementing such a distributed system and its algorithms was always on my stack. This implementation tries to cover most of the important aspects, yet largely simplified.
The source for this project is rounakdatta/GoDFS.
Building Go Distributed File System Abstracting away the odds Proven systems like Google FileSystem (GFS) and Hadoop Distributed FileSystem have almost made developers take distributed architectures for granted." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/godfs/" />


<meta property="article:published_time" content="2020-08-09T00:00:00&#43;05:30"/>

<meta property="article:modified_time" content="2020-12-30T23:23:23&#43;05:30"/>








<meta name="generator" content="Hugo 0.79.1" />

<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,600" rel="stylesheet">
<style type="text/css">/*https://coolors.co/afd5aa-f0f2ef-a69f98-3d3d3d-8c6057*/
:root {
  --main-color: #8C6056; 
  --secondary-color: #AFD5AA;
  --logo-text-color: #fff;
  --body-text-color: #3d3d3d;
  --heading-text-color: #383838;
  --background-color: #fff;
}</style>
<link href='/css/tachyons.min.css' rel="stylesheet">
<link href='/css/styles.css' rel="stylesheet">


<link rel="icon" 
 
  href='/favicon.ico'

type="image/x-icon"/>

<link href='/feed.xml' rel="alternate" type="application/atom+xml" title="Rounak&#39;s Blog" />
</head>
<body class="global-font">
  <nav class=" flex  justify-between border-box pa3 pl3-l pr2-l mt1 mt0-ns" id="navbar">
  <div class="flex">
    <a class="f4 fw6 ttu no-underline dim bg-main-color pv1 ph2 br2" id="site-title" href='/' title="Home">Rounak&#39;s Blog</a>
  </div>
  
  <div class=" flex-grow  pv1">
    
      <a class="link dim dark-gray f6 dib mr2 mr3-l ttu tracked" href='/about' title="About">About</a>
    
  </div>
  
</nav>
  
<main class="center mv4 content-width ph3">
  <div class="f3 fw6 heading-color heading-font post-title">GoDFS - a simple Distributed FileSystem written in Go</div>
  <p class="silver f6 mt1 mb4 post-meta">
    <time>09 Aug 2020</time> 
     | 
    
    
    tags: [ <a href='/tags/golang' class="link silver">golang</a> <a href='/tags/distributed-systems' class="link silver">distributed-systems</a>  ]
    
  </p>
  <div class="lh-copy post-content"><blockquote>
<p>Redundancy is the key in software engineering ~Paul Klint</p>
</blockquote>
<p>I&rsquo;ve been midway through <a href="https://www.goodreads.com/book/show/23463279-designing-data-intensive-applications">Designing Data-Intensive Applications</a> and implementing such a distributed system and its algorithms was always on my stack. This implementation tries to cover most of the important aspects, yet largely simplified.</p>
<p>The source for this project is <a href="https://github.com/rounakdatta/GoDFS">rounakdatta/GoDFS</a>.</p>
<h2 id="building-go-distributed-file-system">Building Go Distributed File System</h2>
<h3 id="abstracting-away-the-odds">Abstracting away the odds</h3>
<p>Proven systems like <a href="https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf">Google FileSystem (GFS)</a> and <a href="https://hadoop.apache.org/docs/r1.2.1/hdfs%5Fdesign.pdf">Hadoop Distributed FileSystem</a> have almost made developers take distributed architectures for granted. We now regularly use open-source systems like the Hadoop ecosystem tools, managed cloud services without worrying of the underlying engineering behind scaling it across machines, data-centers and continents. In this implementation as well, we have abstracted the working of RPC, filesystem storage considerations, thus making it not production-ready ðŸ˜‰</p>
<figure>
    <img src="/ox-hugo/dynamodb_rant.png"
         alt="Figure 1: Source"/> <figcaption>
            <p>Figure 1: <a href="https://www.jeremydaly.com/takeaways-from-dynamodb-deep-dive-advanced-design-patterns-dat403/">Source</a></p>
        </figcaption>
</figure>

<h3 id="the-pieces">The pieces</h3>
<p>To build a distributed system which stores and serves files on-demand typically needs to have a set of persistent data stores, a coordinating unit and an user-facing dumb client.</p>
<h4 id="datanode">DataNode</h4>
<p>DataNodes in this system are just holding the data and when provided with an address can write data to or read data from that address. The data nodes deal with chunks of data which when aggregated by someone else makes sense. Ideally, the number of data nodes should be greater than one for it to be a distributed system. Also it is not necessary that a single data node would contain every chunk of a particular file.</p>
<h4 id="namenode">NameNode</h4>
<p>The NameNode is ideally a singular central coordinating unit of the entire system. It&rsquo;s responsibilities start from record-keeping of which all data nodes are available/healthy and helping the client decide with where all to put the chunks for an incoming file &amp; where all to fetch the chunks from for a requested file. The name node also knows what is the chunk size (termed BlockSize later) and how many copies of data to keep (ReplicationFactor). The name node is the know-it-all guy of the system and therefore making it&rsquo;s death fatal for the system. Therefore we must have a backup name node (called Secondary NameNode) to which the NameNode is flushing all its meta periodically.</p>
<h4 id="client">Client</h4>
<p>Client does all the talking. Upon the client getting a request from the user interface, it&rsquo;s job is to first contact the NameNode for all the meta information. If it is a file <code>PUT</code> request, name node helps it by providing where all to keep the chunks in (the endpoints of the DataNodes and the target directory path within them). If it is a file <code>GET</code> request, the name node helps it by providing the intrinsic details of where exactly to obtain the chunks from. And thus the loop completes.</p>
<h3 id="the-chunks">The chunks</h3>
<p>We must decide on a BlockSize factor which determines into how many pieces a file is broken into. Of course having this metric too high or low impacts the write and read performances of the system overall, but we need to find a justified value which has been benchmarked. The chunks (henceforth referred to as blocks) are stored as individual files and is indexed by the NameNode through a BlockId. Depending upon ReplicationFactor we might have redundant copies of the same block stored on multiple data nodes.</p>
<h3 id="the-replication">The replication</h3>
<p>Replication is probably the most important factor in this context. We must decide upon the ReplicationFactor considering the cost-reliability trade-off. The replication in this system works as: When the client requests a particular DataNode to write a new block into its file system, the client also supplies with which all data nodes to replicate to. Now as the first data node finishes writing to its own file system, it itself connects to the next replication candidate data node and passes the remaining array of replication candidates. And thus the replication process finishes when the tail of the recursion returns to the client and the replicated file write can be concluded to have succeeded.</p>
<h3 id="the-talking">The talking</h3>
<p>As the client communicates with the NameNode, DataNodes, as the DataNodes whisper to each other, what is the protocol of talking? We are using plain and simple RPC (Remote Procedural Calls) here in this case.</p>
<h2 id="setting-it-up">Setting it up</h2>
<p>You can try GoDFS manually or by setting it up through Docker Compose. We can test and compile it to produce a binary as:</p>
<p><a id="code-snippet--testing and building"></a></p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">make <span style="color:#008000">test</span>
make build
</code></pre></td></tr></table>
</div>
</div><h3 id="natively-on-local-host">Natively on local host</h3>
<p>First, we need to set up the DataNode and NameNode daemons, we are starting 3 data nodes for example, and they are running on the same host:</p>
<p><a id="code-snippet--booting datanodes"></a></p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">./godfs datanode --port <span style="color:#666">7000</span> --data-location .dndata1/
./godfs datanode --port <span style="color:#666">7001</span> --data-location .dndata2/
./godfs datanode --port <span style="color:#666">7002</span> --data-location .dndata3/
</code></pre></td></tr></table>
</div>
</div><p>Next, we are initializing the NameNode providing it with the list of data nodes available. If not provided explicitly, the NameNode tries discovering services in the local host for a particular range of ports.</p>
<p><a id="code-snippet--booting namenode"></a></p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">./godfs namenode --datanodes localhost:7000,localhost:7001,localhost:7002 --block-size <span style="color:#666">10</span> --replication-factor <span style="color:#666">2</span>
</code></pre></td></tr></table>
</div>
</div><p>Now, we are good to try using the client to do the file keeping and fetching operations (let&rsquo;s try with the readme file):</p>
<p><a id="code-snippet--testing client"></a></p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">8
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">./godfs client --namenode localhost:9000 --operation put --source-path ./ --filename README.md
<span style="color:#408080;font-style:italic"># 2020/08/08 18:08:51 NameNode to connect to is localhost:9000</span>
<span style="color:#408080;font-style:italic"># 2020/08/08 18:08:52 Put status: true</span>

./godfs client --namenode localhost:9000 --operation get --filename README.md
<span style="color:#408080;font-style:italic"># 2020/08/08 18:09:00 NameNode to connect to is localhost:9000</span>
<span style="color:#408080;font-style:italic"># 2020/08/08 18:09:00 Get status: true</span>
<span style="color:#408080;font-style:italic"># FILE CONTENTS ...</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="containerized-through-docker-compose">Containerized through Docker Compose</h3>
<p>In the <code>docker-compose.yml</code> file, we try to define the DataNode and NameNode as independent services and the requested number of instances of the same will be spawned up. We have individual <code>Dockerfile</code> s for the DataNode and NameNode.</p>
<p>Assuming we have Docker set up in the host system, we have to build the images first:</p>
<p><a id="code-snippet--building docker images"></a></p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">docker build -t datanode -f daemon/datanode/Dockerfile .
docker build -t namenode -f daemon/namenode/Dockerfile .
docker build -t client -f daemon/client/Dockerfile .
</code></pre></td></tr></table>
</div>
</div><p>Now we can initiate a desired number of containers for DataNode and a single container for NameNode as:</p>
<p><a id="code-snippet--booting the composed containers"></a></p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">docker-compose up --scale <span style="color:#19177c">datanode</span><span style="color:#666">=</span><span style="color:#666">6</span> --remove-orphans --force-recreate
</code></pre></td></tr></table>
</div>
</div><p>Next, we would need a client in the same network to test out requests:</p>
<p><a id="code-snippet--interacting through a client container"></a></p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">docker run -it --network host client
</code></pre></td></tr></table>
</div>
</div><blockquote>
<p>TODO: Here we have allowed the DataNode containers to run within the <strong>host</strong> network, i.e. its processes are now exposed to the host. We need some more sophistication in the isolation here.</p>
</blockquote>
<p>Either way of testing, to test the end-to-end working of the system, we not only want <code>GET</code> Success, but also want to understand when such a DFS can fail. We can fetch the metadata from the NameNode on where all the blocks of a given file are kept. So, theoretically, if <code>replication-factor</code> is 2 and we identify those 2 DataNodes for a particular file BlockId, we can then experiment with the edge cases of distributed systems by killing those two containers. And then we should no longer be able to fetch the complete file (since a part of it does not exist in any of the data nodes). If practice matches the above theory, we are good to go :)!</p>
</div>
</main>
 






<div class="tl fixed list-pages lh-copy" id="contents-list"></div>



<div class="pagination tc tr-l db fixed-l bottom-2-l right-2-l mb3 mb0-l">
  
<a id="scroll-to-top" class="f6 o-0 link br2 ph2 pv1 mb1 bg-main-color pointer" onclick="topFunction()" style="color: #fff; visibility: hidden; display: none; transition: opacity .5s, visibility .5s;" title="back to top">back to top</a>
<br>
  <p class="mb0 mt2">
  <a href="/posts/firefly/">prev post</a>
  <a href="/posts/open-source-tools-everyday/">next post</a>
  </p>
</div>

  <footer class="content-width mt0 mt5-l mb4 f6 center ph3 gray tc tl-l">
  <hr class="dn db-l ml0-l gray w3"><br>
  Powered by <a href="https://gohugo.io/" target="_blank" class="link gray dim">Hugo</a>, based on the <a href="https://github.com/lingxz/er" target="_blank" class="link gray dim">Er</a> theme. <br>
  Written and published right from Emacs Org-mode.
</footer>
  



<script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.min.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.css">
<style>.is-active-link::before { background-color: var(--secondary-color); }</style>




<script type="text/javascript">
var prevScrollpos = window.pageYOffset;
window.onscroll = function() {
  var currentScrollPos = window.pageYOffset;

  
  if (document.getElementById("tag-cloud") !== null) { 
    if (prevScrollpos > currentScrollPos) { 
      document.getElementById("tag-cloud").style.visibility = "visible";
      document.getElementById("tag-cloud").style.opacity = "1";
    } else {
      document.getElementById("tag-cloud").style.visibility = "hidden";
      document.getElementById("tag-cloud").style.opacity = "0";
    }
  }
  

  
  if (document.body.scrollTop > 1000 || document.documentElement.scrollTop > 1000) {
      document.getElementById("scroll-to-top").style.display = "inline";
      document.getElementById("scroll-to-top").style.visibility = "visible";
      document.getElementById("scroll-to-top").style.opacity = "1";
  } else {
      document.getElementById("scroll-to-top").style.visibility = "hidden";
      document.getElementById("scroll-to-top").style.opacity = "0";
  }
  
  prevScrollpos = currentScrollPos;
}


function topFunction() {
  document.body.scrollTop = 0; 
  document.documentElement.scrollTop = 0; 
}






if (document.getElementById("contents-list") !== null && document.getElementsByClassName("post-content").length !== 0) { 
  tocbot.init({
    
    tocSelector: '#contents-list',
    
    contentSelector: '.post-content',
    
    headingSelector: 'h1, h2, h3',
  });
}


</script>




</body>
</html>